version: "3.9"
services:
  backend:
    image: orchestranexus/agentbox:0.0.0
    container_name: mw-backend
    command: bash -c "pip install --no-cache-dir -r /backend/requirements.txt && uvicorn backend_main:app --host 0.0.0.0 --port 8001 --reload"
    network_mode: host
    working_dir: /backend
    volumes:
    - ./backend:/backend
    - ./auth/gcp-oauth.keys.json:/backend/auth/gcp-oauth.keys.json:ro
    - ./backend/requirements.txt:/app/requirements.txt:ro
    - ./backend:/app/backend
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@localhost:5432/mailwhisperer
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - MCP_SERVER_URL=${MCP_SERVER_URL}
      - ADMIN_EMAILS="admin@example.com,testuser@example.com"
      - DOC_PROCESSING_SERVICE_URL=http://localhost:8002/process_pdf/ # Added for new service
    depends_on:
      - db

  db:
    image: postgres:15
    container_name: mw-db
    network_mode: host
    environment:
      POSTGRES_DB: mailwhisperer
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./db/db_init.sql:/docker-entrypoint-initdb.d/db_init.sql

  gmail:
    image: orchestranexus/gmail-mcp:v0.0.0
    command: bash -c "cd /root/.gmail-mcp/  && node /Gmail-MCP-Server-main/dist/index.js auth http://localhost:3000/oauth2callback & /scripts/start_bridge.sh"
    privileged: true
    tty: true
    network_mode: host
    ports:
      - "8000:8000"
    volumes:
      - ./mcp/scripts:/scripts
      - ./mcp/config:/config
      - ./auth/gcp-oauth.keys.json:/root/.gmail-mcp/gcp-oauth.keys.json
    environment:
      MCP_BRIDGE__CONFIG__FILE: /config/bridge_config.json

  frontend:
    image: orchestranexus/python3.11-node24-npx:v0.0.0
    container_name: mw-frontend
    working_dir: /app/frontend
    command: bash -c "npm install & npm run dev"
    network_mode: host
    volumes:
      - ./frontend:/app/frontend
    depends_on:
      - db
      - backend

  doc-processing-service:
    build:
      context: ./doc_processing_service
    container_name: mw-doc-processing-service
    network_mode: host
    environment:
      - DOC_SERVICE_INTERNAL_PORT=8002 # Service will listen on port 8002 on the host
      - TRANSFORMERS_CACHE=/app/huggingface_cache
      # - NVIDIA_VISIBLE_DEVICES=all # Uncomment for local GPU with nvidia-docker
      # - NVIDIA_DRIVER_CAPABILITIES=compute,utility # Uncomment for local GPU
    volumes:
      - ./doc_processing_service/app:/app/app
      - doc_processing_cache:/app/huggingface_cache
    restart: unless-stopped
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
    #   start_period: 60s

volumes:
  db_data:
  doc_processing_cache: # New volume for doc processing model cache
